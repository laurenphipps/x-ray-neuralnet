{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal working notebook imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# importing keras for neural net building\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# scores for understanding results\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# insight into how machine makes decisions\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will retrieve all the pictures in the data set and assign a label based on the folder it was in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to path of the images\n",
    "# These images are split into train/test/validation sets\n",
    "# Then further split by if they have p\n",
    "train_data_dir = 'chest_xray/chest_xray/train/'\n",
    "val_data_dir = 'chest_xray/chest_xray/val/'\n",
    "test_data_dir = 'chest_xray/chest_xray/test/'\n",
    "\n",
    "\n",
    "# getting the testing data\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(64, 64), batch_size=600)\n",
    "\n",
    "# getting the validation set\n",
    "val_generator = ImageDataGenerator().flow_from_directory(\n",
    "        val_data_dir, \n",
    "        target_size=(64, 64), batch_size=16)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator(horizontal_flip=True).flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(64, 64), batch_size=5200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to look at average image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images.reshape(5200,12288)\n",
    "X_test = test_images.reshape(600,12288)\n",
    "X_val = val_images.reshape(16,12288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_labels.T[[1]][0]\n",
    "y_test = test_labels.T[[1]][0]\n",
    "y_val = val_labels.T[[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_classes = 2\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardizing the image values \n",
    "This is done so that instead of a value between 0 and 255 we have a value between 0-1 reprenting how much color is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image augmentation for increas in train data\n",
    "\n",
    "Image augmentation is going to help with overfitting because of how it changes the images. In this case we are going to be flipping images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices['NORMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = train_images[0]\n",
    "label = train_labels[0]\n",
    "print(train_generator.labels[0])\n",
    "plt.imshow(image);\n",
    "#plt.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.expand_dims(image,0)\n",
    "for i in range(9):\n",
    "    augmented_image = data_augmentation(image)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_image[0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model structure\n",
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "# 12288 = 64x64x3 = size of image\n",
    "model.add(Dense(50,activation='relu',input_shape=(12288,)))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=Adam(),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   verbose=1,\n",
    "                   validation_data=(X_val,y_val))\n",
    "\n",
    "score = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu',input_shape=(64,64,3)))\n",
    "#model.add(layers.Conv2D(64, (3,3), activation='relu',input_shape=(64,64,3)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "#model.add(layers.SeparableConv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "#model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, y_train, epochs=5,validation_data=(val_images,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_augmented = tf.keras.Sequential([\n",
    "    data_augmentation,\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu',input_shape=(64,64,3)),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "\n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    \n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(2, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_augmented.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model_augmented.fit(train_images, y_train, epochs=4,validation_data=(val_images,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = model_augmented.evaluate(test_images,test_labels,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_keras = (model_augmented.predict(test_images) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = y_pred_keras.T[[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_labels.T[[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_true, y_pred_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true,y_pred_keras)\n",
    "df_cm = pd.DataFrame(conf_matrix,columns=['Norm','Pneu'],index=['Norm','Pneu'])\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax = sns.set(font_scale=1.4)\n",
    "ax = sns.heatmap(df_cm,cmap='Blues',annot=True,annot_kws={'size':16});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying alex net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(96, (4,4), activation='relu',input_shape=(64,64,3),padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (11,11), activation='relu',input_shape=(64,64,3),padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(384, (3,3), activation='relu',input_shape=(64,64,3),padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(384, (3,3), activation='relu',input_shape=(64,64,3),padding='same'))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3,3), activation='relu',input_shape=(64,64,3),padding='same'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, y_train, epochs=5,validation_data=(val_images,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_images,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for higher accuracym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through research I found that a common method for convolutional layers is having 32-32-64-64 filters in that progression. This worked very well and increase predciton abilites from on averag 0.80 to on average 0.86. After this process due to lack of overfitting I continually added layers until overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing = tf.keras.Sequential([\n",
    "    data_augmentation,\n",
    "\n",
    "    layers.Conv2D(32, kernel_size=(3,3), activation='relu',input_shape=(64,64,3)),\n",
    "    layers.MaxPool2D((2,2),strides=2),\n",
    "\n",
    "    layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2),strides=2),\n",
    "    \n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2),strides=2),\n",
    "    \n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2),strides=2),\n",
    "    \n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    layers.Dense(2, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model_testing.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model_testing.fit(train_images, y_train, epochs=50,validation_data=(val_images,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_testing.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = model_testing.evaluate(test_images,y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine what threshold is going to be the best for out predcitions we are going to show ROC curves for each threshold value. The model predicts how likely it thinks each picture belongs to a class. An example prediction would be \\[0.387,0.613\\] where it thinks it has a 38% chance of not having pneumonia and 61% chance of having pneumonia. The higher we raise the threshold the more confident we have to be that the image has pneumonia for it to be classfied as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = np.arange(0.1,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_roc = y_test.T[[1]][0]\n",
    "def roc_per_thresh(threshs):\n",
    "    rocs = []\n",
    "    for thresh in threshs:\n",
    "        y_pred_roc = (model_testing.predict(test_images) > thresh).astype('int32')\n",
    "        y_pred_roc = y_pred_roc.T[[1]][0]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test_roc, y_pred_roc)\n",
    "        rocs.append([thresh,fpr,tpr])\n",
    "    return rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_values = roc_per_thresh(threshs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(10,10))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "for roc in roc_values:\n",
    "    plt.plot(roc[1],roc[2],label=(round(roc[0],1),round(roc[1][1],2),round(roc[2][1],2)))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(title=['(FPR,TPR)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model_testing.predict(test_images) > 0.4).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.T[[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.T[[1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Pred: {} \\nTrue: {}\".format(y_pred[1],y_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array_to_img(test_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_predictions = (y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_lime = test_images.astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Norm','Pneu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, ax = plt.subplots(5, 3, sharex='col', sharey='row')\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(16)\n",
    "indecies = random.sample(range(sum(bad_predictions)), 5)\n",
    "for j in range(5):\n",
    "    explanation = explainer.explain_instance(test_images_lime[bad_predictions][indecies[j]], \n",
    "                                             model_testing.predict, \n",
    "                                             top_labels=5, hide_color=0, num_samples=1000, \n",
    "                                             random_seed=42)\n",
    "    ax[j,0].imshow(test_images_lime[bad_predictions][indecies[j]])\n",
    "    for i in range(2):\n",
    "        temp, mask = explanation.get_image_and_mask(i, positive_only=True, \n",
    "                                                    num_features=5, hide_rest=True)\n",
    "        ax[j,i+1].imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_labels[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_outline(i):\n",
    "    explanation = explainer.explain_instance(test_images[i].astype('double'), model_testing.predict, top_labels=5, hide_color=0, num_samples=1000)\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "    plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "array_to_img(test_images[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_outline(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_number = 7\n",
    "print(\"Pred: {} \\nTrue: {}\".format(y_pred[pic_number],y_test[pic_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(test_images[pic_number].astype('double'), model_testing.predict, top_labels=5, hide_color=0, num_samples=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Select the same class explained on the figures above.\n",
    "ind =  explanation.top_labels[0]\n",
    "\n",
    "#Map each explanation weight to the corresponding superpixel\n",
    "dict_heatmap = dict(explanation.local_exp[ind])\n",
    "heatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n",
    "\n",
    "#Plot. The visualization makes more sense if a symmetrical colorbar is used.\n",
    "plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
